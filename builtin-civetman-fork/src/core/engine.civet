// --------------------------------------------------------------
// engine.civet â€“ shared BuildEngine for build & watch pipelines 
// decides skip-vs-compile, delegates to pool, then calls writeOutputAndGetResult
// TEST: Watch mode is working!
// --------------------------------------------------------------

fs from "fs-extra"
path from "node:path"
{ WorkerPool } from "../worker/pool.civet"
{ findConfig as findCivetConfig, loadConfig as loadCivetConfig } from "@danielx/civet/config"

// Import helpers and types from the refactored modules.
import { resolveOutputType, makeSignature, fileToOutFile, logDebug } from "../support/utils.civet"
import type { BuildContext } from "../support/config.civet"

{ compile } from "@danielx/civet"
import { rewriteCivetImports } from "../support/import-rewriter.civet"
import type { CompileResult, CivetCompileResult, CompileStateUpdate } from "../types.civet"

export class BuildEngine
    ctx: BuildContext
    pool: WorkerPool
    // Simple in-memory cache to avoid repeated disk reads during watch mode
    contentCache: Map<string, string>
    inFlight: Map<string, Promise<CompileResult>>

    constructor(ctx: BuildContext, workerScriptPath: string)
        @ctx = ctx
        concurrency := Math.max(1, (@ctx.opts.concurrency ?? 2))
        @pool = new WorkerPool(workerScriptPath, concurrency)
        @inFlight = new Map<string, Promise<CompileResult>>()
        @contentCache = new Map<string, string>()

    // Build / rebuild *all* sources currently in ctx.sources
    async buildAll(): Promise<CompileResult[]>
        tasks := @ctx.sources.map (file) => @build(file)
        results := await Promise.allSettled(tasks)
        // Flatten settled results, handling potential top-level errors from build()
        compiledResults: CompileResult[] := []
        for settledResult of results
            if settledResult.status === 'fulfilled'
                compiledResults.push(settledResult.value)
            else
                compiledResults.push({ status: 'error', file: 'unknown', error: settledResult.reason, outFile: '', signature: '' })
        return compiledResults


    // Build a single file. Dedupe if already in progress.
    build(file: string, onProgress?: (result: CompileResult) => void)
        existingTask := @inFlight.get(file)
        if existingTask
            return existingTask
        

        task := @runCompileTask(file).then (result: CompileResult) =>
            onProgress?.(result)
            return result
        .catch (error: unknown) =>
            err := error instanceof Error ? error : new Error(String(error))
            result: CompileResult := { file, status: 'error', error: err, outFile: '', signature: '' }
            onProgress?.(result)
            return result

        // Track promise for deduplication.
        @inFlight.set(file, task)
        // Clean up once finished.
        task.finally => @inFlight.delete(file)
        return task

    async runCompileTask(file: string): Promise<CompileResult>
        isTsx := resolveOutputType(@ctx, file)
        // Reuse cached file content when available to avoid IO on rapid rebuilds
        content := if @contentCache.has(file)
            cachedContent := @contentCache.get(file)
            if cachedContent
                cachedContent
            else 
                // This should never happen if has() returned true, but defensive code is good
                readData := await fs.readFile(file, "utf8")
                @contentCache.set(file, readData)
                readData
            
        else
            readData := await fs.readFile(file, "utf8")
            @contentCache.set(file, readData)
            readData
        
        parseOpts := @ctx.parseOpts
        signature := makeSignature(content, { tsx: isTsx, inlineMap: @ctx.opts.inlineMap, mapFiles: @ctx.opts.mapFiles, configContent: @ctx.configContent })

        // Skip check (respect --force flag)
        prev := @ctx.prevHashes[file]
        expectedOut := fileToOutFile(file, isTsx)
        if !@ctx.opts.force and prev and prev.sig == signature and prev.outFile == expectedOut and await fs.pathExists(expectedOut)
            // Return the skip result - let the caller handle state updates
            logDebug("[COMPILE] Skipping (signature match)", file)
            return { status: "skip", file, outFile: expectedOut, signature: signature, mapFile: @ctx.opts.mapFiles and await fs.pathExists(expectedOut + ".map") ? expectedOut + ".map" : undefined }

        code .= ""
        mapJson .= null

        // Only generate source maps when the user actually wants them
        wantMap := (@ctx.opts.inlineMap != "none") or @ctx.opts.mapFiles

        // Use worker pool if available and concurrency allows, otherwise compile in-process.
        if (@ctx.opts.concurrency ?? 2) > 1 and @pool.poolAvailable
            try
                logDebug("[COMPILE] Compiling with worker", file)
                // parseOpts is pre-sanitized in config.civet to be serializable. No need to re-sanitize.
                workerResult := await @pool.exec({ file, content, isTsx, wantMap, parseOpts: parseOpts })
                if workerResult.ok
                    code = rewriteCivetImports(workerResult.code)
                    mapJson = workerResult.mapJson
                else
                    throw new Error(workerResult.error)
            catch workerErr
                logDebug("[COMPILE] Worker failed, falling back", workerErr)
                compileOpts := {
                    filename: file,
                    ...(wantMap ? { sourceMap: true } : {}),
                    ...(parseOpts ? { parseOptions: parseOpts } : {})
                }
                rawResult := await compile(content, compileOpts)
                compileResult: CivetCompileResult := typeof rawResult === 'string' 
                    ? { code: rawResult } 
                    : rawResult as CivetCompileResult
                code = rewriteCivetImports(compileResult.code)
                if wantMap and compileResult.sourceMap?
                    mapJson = compileResult.sourceMap.json(file, expectedOut)
        else
            logDebug("[COMPILE] Compiling in-process", file)
            compileOpts := {
                filename: file,
                ...(wantMap ? { sourceMap: true } : {}),
                ...(parseOpts ? { parseOptions: parseOpts } : {})
            }
            rawResult := await compile(content, compileOpts)
            compileResult: CivetCompileResult := typeof rawResult === 'string' 
                ? { code: rawResult } 
                : rawResult as CivetCompileResult
            code = rewriteCivetImports(compileResult.code)
            if wantMap and compileResult.sourceMap?
                mapJson = compileResult.sourceMap.json(file, expectedOut)

        // ensure cache stores latest content
        @contentCache.set(file, content)

        return await @_writeOutputAndGetResult(file, isTsx, code, mapJson, signature)

    // Handles writing the output of a successful compilation to disk.
    // This is now an internal method of the engine.
    async _writeOutputAndGetResult(
        file: string,
        isTsx: boolean,
        code: string,
        mapJson: string | null,
        signature: string
    ): Promise<CompileResult>
        expectedOut := file.replace(".civet", isTsx ? ".tsx" : ".ts")
        codeOut .= code
        
        // Inject @ts-nocheck header when compiling to JavaScript mode (parseOptions.js = true)
        if @ctx.parseOpts?.js
            codeOut = "// @ts-nocheck\n" + codeOut
        
        mapFile := expectedOut + ".map"

        if @ctx.opts.inlineMap is "full" and mapJson
            base64Map := Buffer.from(JSON.stringify(mapJson)).toString("base64")
            codeOut += "\n//# sourceMappingURL=data:application/json;base64," + base64Map + "\n"

        if @ctx.opts.mapFiles and mapJson
            await fs.writeFile(mapFile, JSON.stringify(mapJson))

            if @ctx.opts.inlineMap is "fileurl"
                codeOut += "\n//# sourceMappingURL=" + path.basename(mapFile) + "\n"
        
        await fs.writeFile(expectedOut, codeOut)

        // --- Cleanup: remove bygone sibling (.ts vs .tsx) to prevent stale duplicates ---
        siblingOut := file.replace('.civet', isTsx ? '.ts' : '.tsx')
        try
            if siblingOut != expectedOut && await fs.pathExists(siblingOut)
                await fs.unlink(siblingOut)
            if await fs.pathExists(siblingOut + '.map')
                await fs.unlink(siblingOut + '.map')
        catch (err: unknown)
            logDebug("[WRITE] Best-effort cleanup of sibling file failed.", { siblingOut, err })

        logDebug("built", file)
        return { status: "built", file, outFile: expectedOut, signature, mapFile: @ctx.opts.mapFiles and mapJson ? mapFile : undefined }

    // Handle a source deletion - returns state update describing what needs to be deleted.
    createRemoveUpdate(file: string): CompileStateUpdate
        // Clear content cache (safe, internal state)
        @contentCache.delete(file)
        
        // Describe which files to delete
        tsFile := file.replace(".civet", ".ts")
        tsxFile := file.replace(".civet", ".tsx")
        
        return {
            outFiles: [],
            newHashes: {},
            filesToDelete: [tsFile, tsxFile, `${tsFile}.map`, `${tsxFile}.map`],
            hashesToDelete: [file]
        }
    

