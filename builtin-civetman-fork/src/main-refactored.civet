// --------------------------------------------------------------
// main-refactored.civet – Experimental rewrite with clean layering
// --------------------------------------------------------------

// ──────────────────────────────────────────────────────────────
// Imports (pure-logic modules come first – no UI side-effects)  
// ──────────────────────────────────────────────────────────────

c from "picocolors"
{ program } from "commander"
fs from "fs-extra"
glob from "fast-glob"
pLimit from "p-limit"
{ join } from "node:path"
path from "node:path"
os from "node:os"
crypto from "node:crypto"
chokidar from "chokidar"
ora from "ora"
{ compile } from "@danielx/civet"
{ parseTree as jsoncParseTree, findNodeAtLocation as jsoncFindNodeAtLocation, getNodeValue as jsoncGetNodeValue, modify as jsoncModify, applyEdits as jsoncApplyEdits } from "jsonc-parser"

// ──────────────────────────────────────────────────────────────
// Types & defaults                                                
// ──────────────────────────────────────────────────────────────

type Options =
    tsx: boolean,
    gitIgnore: boolean,
    vscodeHide: boolean,
    inlineMap: "full" | "fileurl" | "none",
    mapFiles: boolean,
    outTs?: string[],      // folders
    outTsx?: string[],
    concurrency?: number

defaultOpts: Options :=
    tsx: false,
    gitIgnore: true,
    vscodeHide: true,
    inlineMap: "full",
    mapFiles: false,
    concurrency: Math.min(2, (os.cpus()?.length || 2))

// ──────────────────────────────────────────────────────────────
// Build-state layer – Pure functions operating on BuildContext  
// ──────────────────────────────────────────────────────────────

// A central object that holds all mutable state. Tests can mock it easily.
type BuildContext =
    opts: Options,
    cwd: string,
    // list of civet source files (fixed for single build run)
    sources: string[],
    // outputs produced in this run
    outFiles: Set<string>,
    // previous manifest data (for pruning)
    prevGenerated: Set<string>,
    // previous content hashes for incremental builds
    prevHashes: Record<string, { hash: string, outFile: string }>,
    // new hashes produced this run
    newHashes: Record<string, { hash: string, outFile: string }>

// ---------------- helper utils (pure) ----------------

computeHash := (input: string): string =>
    crypto.createHash("sha1").update(input).digest("hex")

// ---------------- debug ----------------
outputDebug := true  // enable by env var
logDebug := (...args: any[]) =>
    if outputDebug
        console.log("[civetman-debug]", ...args)

// ------------------------------------------------------------------
// Atomic write utility ensures we never leave partially-written files
// ------------------------------------------------------------------
safeWrite := async (filePath: string, data: string | Buffer) =>
    await fs.ensureDir(path.dirname(filePath))
    tmp := filePath + "." + crypto.randomUUID() + ".civetmantmp"
    await fs.writeFile(tmp, data)
    await fs.rename(tmp, filePath)

// Remove stray *.civetmantmp files that belong to our outputs
cleanupTmpFiles := async (cwd: string) =>
    tmpFiles := await glob("**/*.civetmantmp", cwd: cwd)
    for tmp of tmpFiles
        try
            await fs.unlink(tmp)
        catch _
            continue

fileToOutFile := (file: string, tsx: boolean) =>
    file.replace(".civet", tsx ? ".tsx" : ".ts")

// Decide ts vs tsx based on CLI options / folder flags
resolveOutputType := (ctx: { cwd: string, opts: Options }, file: string): boolean =>
    relativeFile := path.relative(ctx.cwd, file)

    findLongestMatch := (dirs: string[]) =>
        matches := (dirs || []).filter((dir: string) => {
            normalized := path.normalize(dir)
            return normalized === '.' || relativeFile.startsWith(normalized + path.sep)
        })
        if !matches.length return null
        matches.sort((a,b) => b.length - a.length)[0]

    tsxMatch := findLongestMatch(ctx.opts.outTsx ? ctx.opts.outTsx : [])
    tsMatch  := findLongestMatch(ctx.opts.outTs  ? ctx.opts.outTs  : [])
    if tsxMatch && tsMatch
        return tsxMatch.length >= tsMatch.length
    if tsxMatch return true
    if tsMatch  return false
    return ctx.opts.tsx

collectDirs := (val: string, prev: string[]) =>
    // Accept comma-separated lists or repeatable flags.
    prev.concat(
        val.split(",")
            .map((s: string) => s.trim())
            .filter((s): s is string => !!s)
    )

// ---------------- manifest helpers (pure fs) ----------------
manifestDir := (cwd: string) => join(cwd, ".civetman")
manifestFile := (cwd: string) => join(manifestDir(cwd), "manifest.json")
hashManifestFile := (cwd: string) => join(manifestDir(cwd), "hashes.json")

loadJSON := async (file: string, fallback: any) =>
    if await fs.exists(file)
        try
            JSON.parse(await fs.readFile(file, "utf8"))
        catch
            fallback
    else
        fallback

saveJSON := async (file: string, data: any) =>
    await fs.ensureDir(path.dirname(file))
    await safeWrite(file, JSON.stringify(data, null, 2))

loadPrevState := async (cwd: string) =>
    manifestObj := await loadJSON(manifestFile(cwd), { generated: [] })
    prevGenerated := new Set(manifestObj.generated as string[])
    prevHashes := await loadJSON(hashManifestFile(cwd), {}) as Record<string, { hash: string, outFile: string }>
    { prevGenerated, prevHashes }

saveNewState := async (ctx: BuildContext) =>
    logDebug("[STATE] Saving new state", { outFiles: [...ctx.outFiles], hashCount: Object.keys(ctx.newHashes).length })
    allHashes := { ...ctx.prevHashes, ...ctx.newHashes }
    await saveJSON(manifestFile(ctx.cwd), { version: 1, generated: [...ctx.outFiles] })
    await saveJSON(hashManifestFile(ctx.cwd), allHashes)
    logDebug("[STATE] State saved successfully")

// ---------------- compilation (pure, worker-thread ready) ----------------
compileSource := async (ctx: BuildContext, file: string) => {
    // decide output type & expected filename
    isTsx := resolveOutputType(ctx, file)
    expectedOut := fileToOutFile(file, isTsx)
    logDebug("[COMPILE] Starting compilation", { file, expectedOut, isTsx })

    // incremental skip logic
    content := await fs.readFile(file, "utf8")
    newHash := computeHash(content)
    prev := ctx.prevHashes[file]
    logDebug("[COMPILE] Hash check", { file, newHash, prevHash: prev?.hash })

    try
        if prev && prev.hash == newHash && prev.outFile == expectedOut && await fs.exists(expectedOut)
            sourceMtime := (await fs.stat(file)).mtimeMs
            outMtime := (await fs.stat(expectedOut)).mtimeMs
            logDebug("[COMPILE] Checking mtimes", { file, sourceMtime, outMtime })
            if outMtime > sourceMtime
                logDebug("[COMPILE] Skipping (up to date)", file)
                ctx.outFiles.add(expectedOut)
                ctx.newHashes[file] = { hash: newHash, outFile: expectedOut }
                return { status: "skip", file, outFile: expectedOut }
    catch _
        logDebug("[COMPILE] Error during mtime check", file)
        // if stat fails, just fall through to build
    
    // actual compile
    try
        logDebug("[COMPILE] Starting actual compilation", file)
        { code, sourceMap } := await compile(content, { filename: file, sourceMap: true }) as { code: string, sourceMap: any }
        logDebug("[COMPILE] Compilation successful", file)

        // --- Source-map handling -----------------------------------------
        codeOut .= code
        mapFile := expectedOut + ".map"

        if ctx.opts.inlineMap == "full"
            mapJson := sourceMap.json(file, expectedOut)
            base64Map := Buffer.from(JSON.stringify(mapJson)).toString("base64")
            codeOut += "\n//# sourceMappingURL=data:application/json;base64," + base64Map + "\n"

        if ctx.opts.mapFiles
            await safeWrite(mapFile, JSON.stringify(sourceMap.json(file, expectedOut)))

            if ctx.opts.inlineMap == "fileurl"
                codeOut += "\n//# sourceMappingURL=" + path.basename(mapFile) + "\n"

        await safeWrite(expectedOut, codeOut)
        ctx.outFiles.add expectedOut
        ctx.newHashes[file] = { hash: newHash, outFile: expectedOut }
        logDebug("built", file)
        return { status: "built", file, outFile: expectedOut }
    catch e
        // propagate error – UI layer decides what to log/exit
        throw e
}

// ---------------- task-queue orchestrator ----------------
compileAll := async (ctx: BuildContext, onProgress?: (result: any) => void) => {
    concurrency: number := Math.max(1, ctx.opts.concurrency ?? defaultOpts.concurrency ?? 2)
    limitFn := pLimit(concurrency)

    handleResult := (promise: Promise<any>, file: string) =>
        promise.then((value: any) => {
            onProgress?.({ ...value, status: value.status })
        }).catch((error: any) => {
            onProgress?.({ file, status: 'error', error })
            throw error
        })
    
    tasks := ctx.sources.map((file) => limitFn(() => handleResult(compileSource(ctx, file), file)))
    
    return Promise.allSettled(tasks)
}

// ---------------- side-effect helpers (IDE, gitignore) ----------------
syncIDEConfigs := async (ctx: BuildContext) =>
    await addVscodeExcludes(ctx)
    await addGitignoreEntries(ctx)

addVscodeExcludes := async (ctx: BuildContext) =>
    // Build the list of patterns we should hide inside VS Code
    files .= [...ctx.outFiles]
    if ctx.opts.mapFiles
        files = [...files, ...files.map((f: string) => f + ".map")]
    
    placeholder := "below is generated by civetman"
    configKey := "files.exclude"
    tmpGlob := "**/*.civetmantmp"

    vscodeDir := join(ctx.cwd, ".vscode")
    settingsFile := join(vscodeDir, "settings.json")

    await fs.ensureDir(vscodeDir)
    await fs.ensureFile(settingsFile)

    content := await fs.readFile(settingsFile, "utf8")
    errors := [] as any[]
    tree := jsoncParseTree(content, errors, { allowTrailingComma: true })
    if !tree
        // cannot parse settings, bail early
        return

    node := jsoncFindNodeAtLocation(tree, [configKey])
    existing := (node ? jsoncGetNodeValue(node) : {}) as Record<string, boolean>

    // Preserve any excludes that are not ours
    manual := Object.entries(existing).reduce((acc: Record<string, boolean>, [k,v]) =>
        if k != placeholder && !files.includes(k)
            acc[k] = v
        acc
    , {})

    newExclude := if ctx.opts.vscodeHide
        dynamic := files.reduce((acc: Record<string, boolean>, f: string) => ({ ...acc, [f]: true }), {})
        dynamic[tmpGlob] = true
        { ...manual, [placeholder]: true, ...dynamic }
    else
        manual

    edits := jsoncModify(content, [configKey], newExclude, { formattingOptions: { insertSpaces: true, tabSize: 2 } })
    newContent := jsoncApplyEdits(content, edits)
    if newContent != content
        await fs.writeFile(settingsFile, newContent, "utf8")
    return

addGitignoreEntries := async (ctx: BuildContext) =>
    gitignorePath := join(ctx.cwd, ".gitignore")
    startMarker := "# civetman:start - Managed by civetman. DO NOT EDIT THIS BLOCK."
    endMarker := "# civetman:end - End of civetman managed block."

    await fs.ensureFile(gitignorePath)
    original .= await fs.readFile(gitignorePath, "utf8")

    generatedFiles .= [...ctx.outFiles]
    if ctx.opts.mapFiles
        generatedFiles = [...generatedFiles, ...generatedFiles.map((f: string) => f + ".map")]

    startIdx := original.indexOf(startMarker)
    endIdx := startIdx == -1 ? -1 : original.indexOf(endMarker, startIdx + startMarker.length)

    [before, after] := if startIdx != -1 && endIdx != -1
        [original.substring(0, startIdx), original.substring(endIdx + endMarker.length)]
    else
        [original, ""]

    managedBlock := if ctx.opts.gitIgnore
        [startMarker, ...generatedFiles, endMarker].join("\n")
    else
        ""

    combined := (before.trimEnd() + "\n\n" + managedBlock + "\n\n" + after.trimStart()).trimEnd() + "\n"

    if combined != original
        await fs.writeFile(gitignorePath, combined, "utf8")
    return

// Ensure .civetman/ dir is ignored by git
ensureGitignoreManifestEntry := async (cwd: string) =>
    gitignoreFile := join(cwd, ".gitignore")
    await fs.ensureFile(gitignoreFile)
    entry := "/.civetman/"
    content := await fs.readFile(gitignoreFile, "utf8")
    if !content.split("\n").map((l) => l.trim()).includes(entry)
        await fs.appendFile(gitignoreFile, "\n" + entry + "\n")

// ---------------- helper to prune stale outputs ----------------
pruneStaleOutputs := async (ctx: BuildContext) =>
    stale := [...ctx.prevGenerated].filter((f) => !ctx.outFiles.has(f))
    for file of stale
        try
            if await fs.exists(join(ctx.cwd, file))
                await fs.unlink(join(ctx.cwd, file))
            if await fs.exists(join(ctx.cwd, file + ".map"))
                await fs.unlink(join(ctx.cwd, file + ".map"))
        catch _
            // best effort – ignore deletion errors
            continue
    return

// ---------------- top-level build function (pure-ish) ----------------
runBuild := async (cwd: string, opts: Options) =>
    // Step 0: scrub temp files from previous aborted runs
    await cleanupTmpFiles(cwd)
    await ensureGitignoreManifestEntry(cwd)

    // Step 1: collect source files
    sources := await glob("**/*.civet", ignore: ["node_modules/**/*", "dist/**/*"], cwd: cwd)

    // Step 2: load previous state and create context
    { prevGenerated, prevHashes } := await loadPrevState(cwd)
    ctx: BuildContext :=
        opts: opts,
        cwd: cwd,
        sources: sources,
        outFiles: new Set<string>(),
        prevGenerated: prevGenerated,
        prevHashes: prevHashes,
        newHashes: {}

    // Step 3: build all, with progress reporting
    spinner := ora(c.blue("Building Civet files")).start()
    hadError .= false
    builtCount .= 0
    skippedCount .= 0

    onProgress := (res: any) => {
        if res.status == 'built'
            spinner.succeed(c.cyan(res.file) + " -> " + c.green(res.outFile))
            builtCount++
        else if res.status == 'skip'
            skippedCount++
        else if res.status == 'error'
            hadError = true
            spinner.fail(c.red(`Error compiling ${res.file}`))
            console.error(res.error)
    }

    await compileAll(ctx, onProgress)
    
    finalMessage .= `Built ${builtCount} file(s)`
    if skippedCount > 0
        finalMessage = `${finalMessage}, ${skippedCount} skipped`

    if !hadError
        spinner.succeed(c.green(`Build complete! ${finalMessage}`))
    else
        spinner.fail(c.red(`Build failed. ${finalMessage}`))

    // Step 4: prune stale outputs & save new state
    await pruneStaleOutputs(ctx)

    await saveNewState(ctx)

    // Step 5: IDE / VCS hygiene
    await syncIDEConfigs(ctx)

    if hadError
        throw new Error("Build failed with errors")

    // Make sure the returned context is up-to-date for watch mode
    ctx.prevGenerated = new Set([...ctx.outFiles])
    ctx.prevHashes = { ...ctx.prevHashes, ...ctx.newHashes }
    ctx.newHashes = {}

    return ctx

// ──────────────────────────────────────────────────────────────
// UI layer – Responsible for colours, spinners, CLI exit codes   
// ──────────────────────────────────────────────────────────────

// CLI command – build
registerBuildCommand := =>
    program.command "build"
        .description "One-shot compile of all .civet files"
        .action async =>
            cwd := process.cwd()
            opts := { ...defaultOpts, ...program.opts<Options>() }
            try
                await runBuild(cwd, opts)
                console.log c.green("\nCivetman finished building!")
            catch e
                // runBuild will have already logged details
                process.exitCode = 1
                return

// ---------------- watch mode helpers ----------------
createWatcher := (cwd: string) ->
    chokidar.watch(cwd, {
        ignored: [/node_modules/, /dist/, /(^|[\/\\])\../], // ignore dotfiles
        persistent: true,
        ignoreInitial: true,
        usePolling: true, // for max reliability in tests
        interval: 100,
        binaryInterval: 300,
        awaitWriteFinish: {
            stabilityThreshold: 100,
            pollInterval: 100
        }
    })

// Helper to add all watch-event listeners to a chokidar watcher instance
attachWatchHandlers := (watcher: any, 
                        ctx: BuildContext, 
                        cwd: string, 
                        saveStateAndSync: () => void, 
                        rebuildOne: (file: string) => void) ->
    watcher.on 'ready', ->
        logDebug("[WATCHER] Initial scan complete and ready for changes")
        logDebug("[WATCHER] Watched paths:", watcher.getWatched())
        console.log(c.blue("Watching for changes"))

    watcher.on 'all', (event: string, changedPath: string) ->
        if !changedPath.endsWith('.civet') return // only care about civet files
        logDebug("[WATCHER] Event:", event, "on path:", changedPath)

    watcher.on 'error', (err: unknown) ->
        logDebug("[WATCHER] Error in watcher:", err)

    watcher.on "add", (abs: string) ->
        file := path.relative(cwd, abs)
        logDebug("[WATCHER_ADD] File added", file)
        if !ctx.sources.includes(file)
            ctx.sources.push file
            logDebug("[WATCHER_ADD] Added to sources list", file)
        rebuildOne(file)
    watcher.on "change", (abs: string) ->
        file := path.relative(cwd, abs)
        logDebug("[WATCHER_CHANGE] File changed", file)
        rebuildOne(file)
    watcher.on "unlink", async (abs: string) =>
        file := path.relative(cwd, abs)
        logDebug("[WATCHER_UNLINK] File removed", file)
        ctx.sources = ctx.sources.filter((f: string) => f != file)
        delete ctx.prevHashes[file]
        delete ctx.newHashes[file]
        tsFile := fileToOutFile(file, false)
        tsxFile := fileToOutFile(file, true)
        for out of [tsFile, tsxFile]
            try {
                if await fs.exists(out)
                    logDebug("[WATCHER_UNLINK] Removing output file", out)
                    await fs.unlink(out)
                if await fs.exists(out + ".map")
                    logDebug("[WATCHER_UNLINK] Removing map file", out + ".map")
                    await fs.unlink(out + ".map")
            } catch (e) {
                logDebug("[WATCHER_UNLINK] Error removing file", out, e)
            }
            ctx.outFiles.delete(out)
        saveStateAndSync()

// ---------------- watch mode ----------------
registerDevCommand := =>
    logDebug("[WatchMode] Registering dev command")
    devAction := async (): Promise<void> =>
        logDebug("[WatchMode] Executing dev action")
        cwd := process.cwd()
        opts := { ...defaultOpts, ...program.opts<Options>() }
        try
            console.log c.blue("Civetman starts building in watch mode…\n")
            ctx := await runBuild(cwd, opts)
            console.log c.green("Initial build complete! Watching for changes…\n")
            
            saveStateAndSync := debounce(async =>
                logDebug("[STATE_SYNC] Starting state sync")
                ctx.prevHashes = { ...ctx.prevHashes, ...ctx.newHashes }
                ctx.newHashes = {}
                await saveNewState(ctx)
                await syncIDEConfigs(ctx)
                logDebug("[STATE_SYNC] State sync complete")
            , 800)

            // Define rebuildOne before creating watcher so it is in scope
            rebuildOne := async (file: string) =>
                logDebug("[REBUILD_ONE] Starting rebuild for", file)
                try
                    result := await compileSource(ctx, file)
                    if result.status == 'built'
                        logDebug("[REBUILD_ONE] Successfully built", file, "->", result.outFile)
                        console.log c.green('  ✓ ' + c.cyan(result.file) + " -> " + c.green(result.outFile))
                    saveStateAndSync()
                catch e
                    logDebug("[REBUILD_ONE] Error compiling", file, e)
                    console.error("Civetman error compiling", file, e)

            logDebug("[WATCHER] Setting up watcher in directory:", path.resolve(cwd))
            watcher := createWatcher(cwd)
            logDebug("[WATCHER] Watcher instance created:", !!watcher)
            attachWatchHandlers(watcher, ctx, cwd, saveStateAndSync, rebuildOne)
            
            process.on "SIGINT", async =>
                watcher.close()
                // Persist final state before exiting
                ctx.prevHashes = { ...ctx.prevHashes, ...ctx.newHashes }
                ctx.newHashes = {}
                await saveNewState(ctx)
                console.log("\nCivetman watch stopped.")
                process.exit()
        catch e
            console.error c.red("Watch mode failed"), e
            process.exitCode = 1
    program.command "dev"
        .description "Watch .civet files and rebuild on change"
        .action devAction

export default () =>
    // top-level CLI wiring
    program
        .name "civetman"
        .description "Use Civet language in any project – build or watch .civet files"
        .version "0.1.0"
        .option("-x, --tsx", "Generate .tsx files instead of .ts", defaultOpts.tsx)
        .option("--out-ts <dir>", "Directory to emit .ts files (repeatable or comma-separated)", collectDirs, [] as string[])
        .option("--out-tsx <dir>", "Directory to emit .tsx files (repeatable or comma-separated)", collectDirs, [] as string[])
        .option("--no-git-ignore", "Disable writing generated files to .gitignore")
        .option("--no-vscode-hide", "Disable hiding generated files in VS Code")
        .option("--inline-map <mode>", "Inline source map mode", defaultOpts.inlineMap)
        .option("--map-files", "Emit external .map files")
        .option("--concurrency <number>", "Max parallel compilations", (val) => parseInt(val, 10))

    registerBuildCommand()
    registerDevCommand()

    program.parse(process.argv)

// --------------------------------------------------------------
// End of experimental refactor skeleton
// --------------------------------------------------------------

// Lightweight debounce util for watch-mode side-effects
debounce := (func: Function, timeout = 1000) ->
    timer: NodeJS.Timeout | null .= null
    (...args: any[]) ->
        logDebug("[DEBOUNCE] Debouncing call with args", args)
        if timer?
            logDebug("[DEBOUNCE] Clearing previous timer")
            clearTimeout(timer)
        timer = setTimeout (->
            logDebug("[DEBOUNCE] Executing debounced function")
            func(...args)
        ), timeout

export computeHash, resolveOutputType, defaultOpts