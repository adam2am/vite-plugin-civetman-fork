// --------------------------------------------------------------
// engine.civet â€“ shared BuildEngine for build & watch pipelines 
// decides skip-vs-compile, delegates to pool, then calls writeOutputAndGetResult
// TEST: Watch mode is working!
// --------------------------------------------------------------

fs from "fs-extra"
{ WorkerPool } from "./workerPool.civet"

// Import helpers and types from the main module.
{   writeOutputAndGetResult,
    resolveOutputType,
    makeSignature,
    fileToOutFile,
    logDebug,
    type BuildContext 
} from "./main.civet"

{ compile } from "@danielx/civet"
import type { CompileResult, CivetCompileResult, CompileStateUpdate } from "./types.civet"

export class BuildEngine
    ctx: BuildContext
    pool: WorkerPool
    // Simple in-memory cache to avoid repeated disk reads during watch mode
    contentCache: Map<string, string>
    inFlight: Map<string, Promise<CompileResult>>

    constructor(ctx: BuildContext)
        @ctx = ctx
        concurrency := Math.max(1, (@ctx.opts.concurrency ?? 2))
        @pool = new WorkerPool(concurrency)
        @inFlight = new Map<string, Promise<CompileResult>>()
        @contentCache = new Map<string, string>()

    // Build / rebuild *all* sources currently in ctx.sources
    async buildAll(onProgress?: (result: CompileResult) => void)
        tasks := @ctx.sources.map (file) => @build(file, onProgress)
        await Promise.allSettled(tasks)

    // Build all sources and return results with state updates
    async buildAllWithStateUpdates(): Promise<{ results: CompileResult[], stateUpdates: CompileStateUpdate[] }>
        results: CompileResult[] := []
        stateUpdates: CompileStateUpdate[] := []
        
        for file of @ctx.sources
            { result, stateUpdate } := await @buildWithStateUpdate(file)
            results.push(result)
            stateUpdates.push(stateUpdate)
        
        return { results, stateUpdates }

    // Build a single file and return both result and state update
    async buildWithStateUpdate(file: string): Promise<{ result: CompileResult, stateUpdate: CompileStateUpdate }>
        result := await @runCompileTask(file)
        stateUpdate := await @createStateUpdate(file, result)
        return { result, stateUpdate }

    // Create state update from compile result
    async createStateUpdate(file: string, result: CompileResult): Promise<CompileStateUpdate>
        outFiles: string[] := []
        newHashes: Record<string, { sig: string, outFile: string }> := {}
        filesToDelete: string[] := []

        if result.status === "built" or result.status === "skip"
            outFiles.push(result.outFile)
            newHashes[file] = { sig: result.signature, outFile: result.outFile }
            
            // Add map file if it exists
            if @ctx.opts.mapFiles and await fs.pathExists(result.outFile + ".map")
                outFiles.push(result.outFile + ".map")

        return { outFiles, newHashes, filesToDelete }

    // Build a single file. Dedupe if already in progress.
    build(file: string, onProgress?: (result: CompileResult) => void)
        existingTask := @inFlight.get(file)
        if existingTask
            return existingTask
        

        task := @runCompileTask(file).then (result: CompileResult) =>
            onProgress?.(result)
            return result
        .catch (error: unknown) =>
            err := error instanceof Error ? error : new Error(String(error))
            result: CompileResult := { file, status: 'error', error: err, outFile: '', signature: '' }
            onProgress?.(result)
            return result

        // Track promise for deduplication.
        @inFlight.set(file, task)
        // Clean up once finished.
        task.finally => @inFlight.delete(file)
        return task

    async runCompileTask(file: string): Promise<CompileResult>
        isTsx := resolveOutputType(@ctx, file)
        // Reuse cached file content when available to avoid IO on rapid rebuilds
        content := if @contentCache.has(file)
            cachedContent := @contentCache.get(file)
            if cachedContent
                cachedContent
            else 
                // This should never happen if has() returned true, but defensive code is good
                readData := await fs.readFile(file, "utf8")
                @contentCache.set(file, readData)
                readData
            
        else
            readData := await fs.readFile(file, "utf8")
            @contentCache.set(file, readData)
            readData
        // Reuse parseOptions loaded once at the start of the build run
        parseOpts := @ctx.parseOpts

        signature := makeSignature(content, { tsx: isTsx, inlineMap: @ctx.opts.inlineMap, mapFiles: @ctx.opts.mapFiles, parseOpts })

        // Skip check
        prev := @ctx.prevHashes[file]
        expectedOut := fileToOutFile(file, isTsx)
        if prev and prev.sig == signature and prev.outFile == expectedOut and await fs.pathExists(expectedOut)
            // Return the skip result - let the caller handle state updates
            logDebug("[COMPILE] Skipping (signature match)", file)
            return { status: "skip", file, outFile: expectedOut, signature: signature }

        code .= ""
        mapJson .= null

        // Only generate source maps when the user actually wants them
        wantMap := (@ctx.opts.inlineMap != "none") or @ctx.opts.mapFiles

        // Use worker pool if available and concurrency allows, otherwise compile in-process.
        if (@ctx.opts.concurrency ?? 2) > 1 and @pool.poolAvailable
            try
                logDebug("[COMPILE] Compiling with worker", file)
                workerResult := await @pool.exec({ file, content, isTsx, wantMap, parseOpts })
                if workerResult.ok
                    code = workerResult.code
                    mapJson = workerResult.mapJson
                else
                    throw new Error(workerResult.error)
            catch workerErr
                logDebug("[COMPILE] Worker failed, falling back", workerErr)
                compileOpts := {
                    filename: file,
                    sourceMap: wantMap,
                    ...(parseOpts ? { parseOptions: parseOpts } : {})
                }
                rawResult := await compile(content, compileOpts)
                compileResult: CivetCompileResult := typeof rawResult === 'string' 
                    ? { code: rawResult } 
                    : rawResult as CivetCompileResult
                code = compileResult.code
                if wantMap and compileResult.sourceMap?
                    mapJson = compileResult.sourceMap.json(file, expectedOut)
        else
            logDebug("[COMPILE] Compiling in-process", file)
            compileOpts := {
                filename: file,
                sourceMap: wantMap,
                ...(parseOpts ? { parseOptions: parseOpts } : {})
            }
            rawResult := await compile(content, compileOpts)
            compileResult: CivetCompileResult := typeof rawResult === 'string' 
                ? { code: rawResult } 
                : rawResult as CivetCompileResult
            code = compileResult.code
            if wantMap and compileResult.sourceMap?
                mapJson = compileResult.sourceMap.json(file, expectedOut)

        // ensure cache stores latest content
        @contentCache.set(file, content)

        return await writeOutputAndGetResult(@ctx, file, isTsx, code, mapJson, signature)

    // Handle a source deletion - returns state update describing what needs to be deleted.
    createRemoveUpdate(file: string): CompileStateUpdate
        // Clear content cache (safe, internal state)
        @contentCache.delete(file)
        
        // Describe which files to delete
        tsFile := file.replace(".civet", ".ts")
        tsxFile := file.replace(".civet", ".tsx")
        
        return {
            outFiles: [],
            newHashes: {},
            filesToDelete: [tsFile, tsxFile, `${tsFile}.map`, `${tsxFile}.map`],
            hashesToDelete: [file]
        }
    

