// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Imports (pure-logic modules come first â€“ no UI side-effects)  
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

c from "picocolors"
{ program } from "commander"
fs from "fs-extra"
glob from "fast-glob"
{ join } from "node:path"
path from "node:path"
os from "node:os"
{ createHash, randomUUID } from "node:crypto"
chokidar from "chokidar"
ora from "ora"
{ compile } from "@danielx/civet"
{ parseTree as jsoncParseTree, findNodeAtLocation as jsoncFindNodeAtLocation, getNodeValue as jsoncGetNodeValue, modify as jsoncModify, applyEdits as jsoncApplyEdits } from "jsonc-parser"
{ createRequire } from "node:module"
type { ParseError } from "jsonc-parser"
{ BuildEngine } from "./engine.civet"
{ loadHashesFromJSONL, writeHashesToJSONL } from "./jsonl-helpers.civet"
micromatch from "micromatch"
{ findConfig as findCivetConfig, loadConfig as loadCivetConfig } from "@danielx/civet/config"

// ------------------------------------------------------------------
// Global build fingerprint â€“ any change forces full rebuilds
// ------------------------------------------------------------------
require := createRequire(import.meta.url)
export buildFingerprint := JSON.stringify({
    civetmanVersion: "0.1.0", // bump on release
    civetCompilerVersion: require("@danielx/civet/package.json").version,
    nodeMajor: process.version.split(".")[0]
})

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Types & defaults                                                
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

type Options =
    tsx: boolean,
    gitIgnore: boolean,
    vscodeHide: boolean,
    inlineMap: "full" | "fileurl" | "none",
    mapFiles: boolean,
    outTs?: string[],      // folders
    outTsx?: string[],
    ignoreFolders?: string[], // folders to completely ignore
    concurrency?: number,
    forcePolling?: boolean

type CompileSuccess = {
    status: "built" | "skip",
    file: string,
    outFile: string,
    signature: string
}
type CompileError = {
    status: "error",
    file: string,
    error: any
}
export type CompileResult = CompileSuccess | CompileError

defaultOpts: Options :=
    tsx: false,
    gitIgnore: true,
    vscodeHide: true,
    inlineMap: "full",
    mapFiles: false,
    ignoreFolders: [],
    concurrency: Math.min(2, (os.cpus()?.length || 2)),
    forcePolling: false

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Build-state layer â€“ Pure functions operating on BuildContext  
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// A central object that holds all mutable state. Tests can mock it easily.
export type BuildContext =
    opts: Options,
    cwd: string,
    // list of civet source files (fixed for single build run)
    sources: string[],
    // outputs produced in this run
    outFiles: Set<string>,
    // previous manifest data (for pruning)
    prevGenerated: Set<string>,
    // previous content hashes for incremental builds
    prevHashes: Record<string, { sig: string, outFile: string }>,
    // new hashes produced this run
    newHashes: Record<string, { sig: string, outFile: string }>

// ---------------- helper utils (pure) ----------------

computeHash := (input: string): string =>
    createHash("sha256").update(input).digest("hex")

// Computes the deterministic build signature shared by all build paths.
// This centralises the formula so changes happen in one place.
export makeSignature := (
    content: string,
    opts: { 
        tsx: boolean, 
        inlineMap: string | boolean | any, 
        mapFiles: boolean, 
        parseOpts?: any }
) : string =>
    computeHash(
        content +
        JSON.stringify({ 
            tsx: opts.tsx, 
            inlineMap: opts.inlineMap, 
            mapFiles: opts.mapFiles, 
            parseOpts: opts.parseOpts ?? null }) +
        buildFingerprint
    )

// ---------------- debug ----------------
// Debug logging â€“ enable by setting CIVETMAN_DEBUG env var.
//   CIVETMAN_DEBUG="*"     â†’ log every category
//   CIVETMAN_DEBUG="WATCHER,COMPILE" â†’ log only those containing this substring (case-insensitive)

debugEnv := process.env.CIVETMAN_DEBUG
outputDebug := !!debugEnv
debugFilters := if debugEnv? and debugEnv != "*" and debugEnv.toLowerCase() != "all"
    new Set(debugEnv.split(",").map((s: string) => s.trim().toUpperCase()).filter((s) => !!s))
else
    null

export logDebug := (...args: any[]) =>
    if !outputDebug return
    tag := typeof args[0] == "string" ? args[0].toUpperCase() : ""
    if debugFilters? and ![...debugFilters].some((f) => tag.includes(f))
        return
    console.log("[civetman-debug]", ...args)

// ------------------------------------------------------------------
// Atomic write utility ensures we never leave partially-written files
// ------------------------------------------------------------------
export safeWrite := async (filePath: string, data: string | Buffer) =>
    await fs.ensureDir(path.dirname(filePath))
    tmp := filePath + "." + randomUUID() + ".civetmantmp"
    await fs.writeFile(tmp, data)
    await fs.rename(tmp, filePath)

// Remove stray *.civetmantmp files that belong to our outputs
cleanupTmpFiles := async (cwd: string) =>
    tmpFiles := await glob("**/*.civetmantmp", cwd: cwd)
    for tmp of tmpFiles
        try
            await fs.unlink(tmp)
        catch _
            continue

export fileToOutFile := (file: string, tsx: boolean) =>
    file.replace(".civet", tsx ? ".tsx" : ".ts")

// Decide ts vs tsx based on CLI options / folder flags
resolveOutputType := (ctx: { cwd: string, opts: Options }, file: string): boolean =>
    relativeFile := path.relative(ctx.cwd, file)

    findLongestMatch := (dirs: string[]) =>
        matches := (dirs || []).filter((dir: string) => {
            normalized := path.normalize(dir)
            return normalized === '.' || relativeFile.startsWith(normalized + path.sep)
        })
        if !matches.length return null
        matches.sort((a,b) => b.length - a.length)[0]

    tsxMatch := findLongestMatch(ctx.opts.outTsx ? ctx.opts.outTsx : [])
    tsMatch  := findLongestMatch(ctx.opts.outTs  ? ctx.opts.outTs  : [])
    if tsxMatch && tsMatch
        return tsxMatch.length >= tsMatch.length
    if tsxMatch return true
    if tsMatch  return false
    return ctx.opts.tsx

collectDirs := (val: string, prev: string[]) =>
    // Accept comma-separated lists or repeatable flags.
    prev.concat(
        val.split(",")
            .map((s: string) => s.trim())
            .filter((s): s is string => !!s)
    )

// ---------------- manifest helpers (pure fs) ----------------
manifestDir := (cwd: string) => join(cwd, ".civetman")
manifestFile := (cwd: string) => join(manifestDir(cwd), "manifest.json")
hashManifestFile := (cwd: string) => join(manifestDir(cwd), "hashes.jsonl")

loadJSON := async (file: string, fallback: any) =>
    if await fs.pathExists(file)
        try
            JSON.parse(await fs.readFile(file, "utf8"))
        catch
            fallback
    else
        fallback

saveJSON := async (file: string, data: any) =>
    await fs.ensureDir(path.dirname(file))
    await safeWrite(file, JSON.stringify(data, null, 2))

loadPrevState := async (cwd: string) =>
    manifestObj := await loadJSON(manifestFile(cwd), { generated: [] })
    prevGenerated := new Set(manifestObj.generated as string[])
    prevHashes := await loadHashesFromJSONL(hashManifestFile(cwd))
    return { prevGenerated, prevHashes }

saveNewState := async (ctx: BuildContext) =>
    logDebug("[STATE] Saving new state", { outFiles: [...ctx.outFiles], newHashCount: Object.keys(ctx.newHashes).length })
    
    // Save generated file list (still full write, but it's small)
    await saveJSON(manifestFile(ctx.cwd), { version: 1, generated: [...ctx.outFiles] })

    // Overwrite the hashes file with the full, compacted state.
    allHashes := { ...ctx.prevHashes, ...ctx.newHashes }
    await writeHashesToJSONL(hashManifestFile(ctx.cwd), allHashes)

    logDebug("[STATE] State saved successfully")

// Handles writing the output of a successful compilation to disk.
// This is used by both the in-process and worker-based compilation paths.
export writeOutputAndGetResult := async (
    ctx: BuildContext,
    file: string,
    isTsx: boolean,
    code: string,
    mapJson: any,
    signature: string
): Promise<CompileResult> => {
    const expectedOut = fileToOutFile(file, isTsx)
    let codeOut = code
    const mapFile = expectedOut + ".map"

    if (ctx.opts.inlineMap == "full" && mapJson) {
        const base64Map = Buffer.from(JSON.stringify(mapJson)).toString("base64")
        codeOut += "\n//# sourceMappingURL=data:application/json;base64," + base64Map + "\n"
    }

    if (ctx.opts.mapFiles && mapJson) {
        await safeWrite(mapFile, JSON.stringify(mapJson))
        ctx.outFiles.add(mapFile)

        if (ctx.opts.inlineMap == "fileurl") {
            codeOut += "\n//# sourceMappingURL=" + path.basename(mapFile) + "\n"
        }
    }

    await safeWrite(expectedOut, codeOut)
    ctx.outFiles.add(expectedOut)
    logDebug("built", file)
    return { status: "built", file, outFile: expectedOut, signature }
}

// ---------------- compilation (pure, worker-thread ready) ----------------
// This function is now only used for IN-PROCESS compilation.
// The worker bypasses this and calls the Civet compiler directly.
export compileSource := async (ctx: BuildContext, file: string): Promise<CompileResult> => 
    // decide output type & expected filename
    isTsx := resolveOutputType(ctx, file)
    expectedOut := fileToOutFile(file, isTsx)
    logDebug("[COMPILE] Starting compilation", { file, expectedOut, isTsx })

    // compute deterministic signature for incremental builds ------------
    content := await fs.readFile(file, "utf8")

    //  -- look for a civet config file (ðŸˆ.json, civetconfig.json, etc.) to include in signature and pass to compiler
    configPath := await findCivetConfig(ctx.cwd)           // might be null if none exists
    civetConfig := (configPath? ? await loadCivetConfig(configPath) : {}) || {}
    parseOpts := civetConfig?.parseOptions

    signature := makeSignature(content, { 
        tsx: isTsx, 
        inlineMap: ctx.opts.inlineMap, 
        mapFiles: ctx.opts.mapFiles, 
        parseOpts })

    prev := ctx.prevHashes[file]
    logDebug("[COMPILE] Sig check", { file, signature, prevSig: prev?.sig })
    try 
        if (prev && prev.sig == signature && prev.outFile == expectedOut && await fs.pathExists(expectedOut)) 
            // outputs are guaranteed to be correct â€“ quick skip
            ctx.outFiles.add(expectedOut)
            if (ctx.opts.mapFiles && await fs.pathExists(expectedOut + ".map")) 
                ctx.outFiles.add(expectedOut + ".map")
            logDebug("[COMPILE] Skipping (signature match)", file)
            return { status: "skip", file, outFile: expectedOut, signature: signature }
    catch _
        logDebug("[COMPILE] Error during sig check", file)
        // fall through to compile on any error
    
    // actual compile
    try 
        logDebug("[COMPILE] Starting actual in-process compilation", file)
        needMap := ctx.opts.inlineMap != "none" || ctx.opts.mapFiles

        compileOptions := {
            filename: file,
            sourceMap: needMap,
            ...(parseOpts ? { parseOptions: parseOpts } : {})
        }

        compileRes := await compile(content, compileOptions) as unknown as { code: string, sourceMap?: any }
        logDebug("[COMPILE] In-process compilation successful", file)

        mapJson := if needMap && compileRes.sourceMap?
            compileRes.sourceMap.json(file, expectedOut)
        else
            null
        return await writeOutputAndGetResult(ctx, file, isTsx, compileRes.code, mapJson, signature)
    catch e
        // propagate error â€“ UI layer decides what to log/exit
        throw e


// ---------------- side-effect helpers (IDE, gitignore) ----------------
syncIDEConfigs := async (ctx: BuildContext) =>
    await addVscodeExcludes(ctx)
    await addGitignoreEntries(ctx)

addVscodeExcludes := async (ctx: BuildContext) =>
    // Build the list of patterns we should hide inside VS Code
    files := [...ctx.outFiles]
    
    placeholder := "below is generated by civetman"
    configKey := "files.exclude"
    tmpGlob := "**/*.civetmantmp"

    vscodeDir := join(ctx.cwd, ".vscode")
    settingsFile := join(vscodeDir, "settings.json")

    await fs.ensureDir(vscodeDir)
    await fs.ensureFile(settingsFile)

    content := await fs.readFile(settingsFile, "utf8")
    errors: ParseError[] := []
    tree := jsoncParseTree(content, errors, { allowTrailingComma: true })
    if !tree
        // cannot parse settings, bail early
        return

    node := jsoncFindNodeAtLocation(tree, [configKey])
    existing := (node ? jsoncGetNodeValue(node) : {}) as Record<string, boolean>

    // Preserve any excludes that are not ours
    manual := Object.entries(existing).reduce((acc: Record<string, boolean>, [k,v]) =>
        if k != placeholder && !files.includes(k)
            acc[k] = v
        acc
    , {})

    newExclude := if ctx.opts.vscodeHide
        dynamic := files.reduce((acc: Record<string, boolean>, f: string) => ({ ...acc, [f]: true }), {})
        dynamic[tmpGlob] = true
        { ...manual, [placeholder]: true, ...dynamic }
    else
        manual

    edits := jsoncModify(content, [configKey], newExclude, { formattingOptions: { insertSpaces: true, tabSize: 2 } })
    newContent := jsoncApplyEdits(content, edits)
    if newContent != content
        await fs.writeFile(settingsFile, newContent, "utf8")
    return

addGitignoreEntries := async (ctx: BuildContext) =>
    gitignorePath := join(ctx.cwd, ".gitignore")
    startMarker := "# civetman:start - Managed by civetman. DO NOT EDIT THIS BLOCK."
    endMarker := "# civetman:end - End of civetman managed block."
    civetmanDirEntry := ".civetman/"

    await fs.ensureFile(gitignorePath)
    original := await fs.readFile(gitignorePath, "utf8")
    lines := original.split('\n')

    // Filter out our managed entries, preserving all other lines.
    // This is self-healing if the file was corrupted.
    nonManagedLines := [] as string[]
    inManagedBlock .= false
    for line of lines
        trimmed := line.trim()
        if trimmed == startMarker
            inManagedBlock = true
            continue
        if trimmed == endMarker
            inManagedBlock = false
            continue
        if trimmed == civetmanDirEntry
            continue
        if !inManagedBlock
            nonManagedLines.push(line)

    // Clean up trailing blank lines to prevent them from accumulating
    while nonManagedLines.length > 0 && nonManagedLines[nonManagedLines.length - 1].trim() === ''
        nonManagedLines.pop()
    
    // Create the new managed block, sorted for determinism
    managedBlock := if ctx.opts.gitIgnore
        [startMarker, ...[...ctx.outFiles].sort(), endMarker].join('\n')
    else
        ""

    // Reconstruct the file content
    newContent .= nonManagedLines.join('\n').trimEnd()
    if newContent
        newContent += '\n\n'
    
    // Add the managed block if it exists
    if managedBlock
        newContent += managedBlock + '\n\n'

    // Always ensure the .civetman directory is ignored
    newContent += civetmanDirEntry + '\n'

    if newContent.trim() != original.trim()
        await safeWrite(gitignorePath, newContent)
    return

// ---------------- helper to prune stale outputs ----------------
pruneStaleOutputs := async (ctx: BuildContext) =>
    stale := [...ctx.prevGenerated].filter((f) => !ctx.outFiles.has(f))
    for file of stale
        try
            if await fs.pathExists(join(ctx.cwd, file))
                await fs.unlink(join(ctx.cwd, file))
        catch _
            // best effort â€“ ignore deletion errors
            continue
    return

// ---------------- top-level build function (pure-ish) ----------------
runBuild := async (cwd: string, opts: Options) =>
    // Step 0: scrub temp files from previous aborted runs
    await cleanupTmpFiles(cwd)

    // Step 1: collect source files
    baseIgnores := ["node_modules/**", "dist/**", "**/*.civetmantmp", "**/.*"]
    userIgnores := (opts.ignoreFolders ?? []).map((d) => path.join(d, "**"))
    ignorePatterns := [...baseIgnores, ...userIgnores]

    sources := await glob("**/*.civet", ignore: ignorePatterns, cwd: cwd, caseSensitiveMatch: false)

    // Step 2: load previous state and create context
    { prevGenerated, prevHashes } := await loadPrevState(cwd)
    ctx: BuildContext :=
        opts: opts,
        cwd: cwd,
        sources: sources,
        outFiles: new Set<string>(),
        prevGenerated: prevGenerated,
        prevHashes: prevHashes,
        newHashes: {}

    // Create the build engine which orchestrates compilation.
    engine := new BuildEngine(ctx)

    // Step 3: build all, with progress reporting
    spinner := ora(c.blue("Building Civet files")).start()
    hadError .= false
    builtCount .= 0
    skippedCount .= 0

    onProgress := (res: any) => {
        if res.status == 'built'
            spinner.succeed(c.cyan(res.file) + " -> " + c.green(res.outFile))
            ctx.newHashes[res.file] = { sig: res.signature, outFile: res.outFile }
            builtCount++
        else if res.status == 'skip'
            ctx.newHashes[res.file] = { sig: res.signature, outFile: res.outFile }
            skippedCount++
        else if res.status == 'error'
            hadError = true
            spinner.fail(c.red(`Error compiling ${res.file}`))
            console.error(res.error)
    }

    await engine.buildAll(onProgress)
    
    finalMessage .= `Built ${builtCount} file(s)`
    if skippedCount > 0
        finalMessage = `${finalMessage}, ${skippedCount} skipped`

    if !hadError
        spinner.succeed(c.green(`Build complete! ${finalMessage}`))
    else
        spinner.fail(c.red(`Build failed. ${finalMessage}`))

    // Step 4: prune stale outputs & save new state
    await pruneStaleOutputs(ctx)

    await saveNewState(ctx)

    // Step 5: IDE / VCS hygiene
    await syncIDEConfigs(ctx)

    if hadError
        throw new Error("Build failed with errors")

    // Make sure the returned context is up-to-date for watch mode
    ctx.prevGenerated = new Set([...ctx.outFiles])
    ctx.prevHashes = { ...ctx.prevHashes, ...ctx.newHashes }
    ctx.newHashes = {}

    return { ctx, engine }

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// UI layer â€“ Responsible for colours, spinners, CLI exit codes   
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// CLI command â€“ build
registerBuildCommand := =>
    program.command "build"
        .description "One-shot compile of all .civet files"
        .action async =>
            cwd := process.cwd()
            opts := { ...defaultOpts, ...program.opts<Options>() }
            engine .= null
            try
                buildResult := await runBuild(cwd, opts)
                engine = buildResult.engine
                console.log c.green("\nCivetman finished building!")
            catch e
                // runBuild will have already logged details
                void (process.exitCode = 1)
            finally
                if engine?
                    await engine.pool.shutdown()
                return

// ---------------- watch mode helpers ----------------
createWatcher := (cwd: string, opts: Options) ->
    // Polling by default only in CI; can be overridden via --force-polling.
    usePolling := opts.forcePolling || !!process.env.CI
    // Build ignore patterns (same logic as build step)
    baseIgnores := ["node_modules/**", "dist/**", "**/*.civetmantmp", "**/.*"]
    userIgnores := (opts.ignoreFolders || []).map((d: string) => path.join(d, "**"))
    ignorePatterns := [...baseIgnores, ...userIgnores]

    // Case-insensitive matcher using micromatch
    ignoreFn := (abs: string) =>
        rel := path.relative(cwd, abs)
        micromatch.isMatch(rel, ignorePatterns, nocase: true)

    chokidar.watch(cwd, {
        ignored: ignoreFn,
        persistent: true,
        ignoreInitial: true,
        usePolling: usePolling,
        interval: 100,
        binaryInterval: 300,
        awaitWriteFinish: {
            stabilityThreshold: 100,
            pollInterval: 100
        }
    })

// ---------------- global watcher registry to avoid duplicate SIGINT logs ----------------

// Define a type for our custom global properties to avoid `as any`.
interface CivetmanGlobal extends NodeJS.Global {
    __civetman_watch_bundles?: Set<any>
    __civetman_sigint_handler_registered?: boolean
}

activeWatchBundles := (global as CivetmanGlobal).__civetman_watch_bundles ?? new Set<any>()
(global as CivetmanGlobal).__civetman_watch_bundles = activeWatchBundles

if !(global as CivetmanGlobal).__civetman_sigint_handler_registered
    (global as CivetmanGlobal).__civetman_sigint_handler_registered = true
    process.on "SIGINT", async =>
        // Gracefully close all active watchers and persist state exactly once
        for entry of activeWatchBundles
            try
                await entry.watcher.close()
                ctxObj := entry.ctx
                ctxObj.prevHashes = { ...ctxObj.prevHashes, ...ctxObj.newHashes }
                ctxObj.newHashes = {}
                await saveNewState(ctxObj)
            catch _
                continue
        // Print shutdown message only once across all processes using a tmp-file lock
        onceFile := path.join(os.tmpdir(), "civetman_watch_stop_once")
        shouldLog .= true
        try
            fs.writeFileSync(onceFile, process.pid.toString(), { flag: 'wx' })
        catch _
            shouldLog = false
        if shouldLog
            console.log("\nCivetman watch stopped (CLI).")
        process.exit()

// Helper to add all watch-event listeners to a chokidar watcher instance
attachWatchHandlers := (watcher: any, 
                        ctx: BuildContext, 
                        cwd: string, 
                        saveStateAndSync: () => void, 
                        engine: BuildEngine) ->
    timers: Map<string, NodeJS.Timeout> := new Map()
    scheduleRebuild := (file: string) =>
        if timers.has(file)
            clearTimeout(timers.get(file)!)
        timers.set(file, setTimeout(() =>
            timers.delete(file)
            compileNow(file)
        , 100))

    compileNow := (file: string) =>
        // Ensure we read the latest file contents; drop any cached entry
        if engine.contentCache? and engine.contentCache.delete?
            engine.contentCache.delete(file)
        engine.build(file, (result: CompileResult) => {
            if result.status == 'built'
                ctx.prevHashes[file] = ctx.newHashes[file] = { sig: result.signature!, outFile: result.outFile! }
                logDebug("[REBUILD_ONE] Built", file, "->", result.outFile!)
                console.log c.green('  âœ“ ' + c.cyan(result.file) + " -> " + c.green(result.outFile!))
            else if result.status == 'skip'
                // update hashes on skip to prevent re-runs
                ctx.prevHashes[file] = ctx.newHashes[file] = { sig: result.signature!, outFile: result.outFile! }
                logDebug("[REBUILD_ONE] Skipped (up to date)", file)
            else if result.status == 'error'
                logDebug("[REBUILD_ONE] Error compiling", file, result.error)
                console.error("Civetman error compiling", file, result.error)
            
            saveStateAndSync()
        })

    watcher.on 'ready', ->
        logDebug("[WATCHER] Initial scan complete and ready for changes")
        logDebug("[WATCHER] Watched paths:", watcher.getWatched())
        console.log(c.blue("Watching for changes"))

    watcher.on 'all', (event: string, changedPath: string) ->
        if !changedPath.endsWith('.civet') return // only care about civet files
        logDebug("[WATCHER] Event:", event, "on path:", changedPath)

    watcher.on 'error', (err: unknown) ->
        logDebug("[WATCHER] Error in watcher:", err)

    watcher.on "add", (abs: string) ->
        // Only react to source .civet files â€“ ignore generated outputs
        unless abs.endsWith('.civet') return
        file := path.relative(cwd, abs)
        logDebug("[WATCHER_ADD] File added", file)
        unless ctx.sources.includes(file)
            ctx.sources.push file
            logDebug("[WATCHER_ADD] Added to sources list", file)
        scheduleRebuild(file)

    watcher.on "change", (abs: string) ->
        unless abs.endsWith('.civet') return
        file := path.relative(cwd, abs)
        logDebug("[WATCHER_CHANGE] File changed", file)
        scheduleRebuild(file)

    watcher.on "unlink", async (abs: string) =>
        unless abs.endsWith('.civet') return
        file := path.relative(cwd, abs) 
        logDebug("[WATCHER_UNLINK] File removed", file)
        await engine.remove(file)
        saveStateAndSync()

// ---------------- watch mode ----------------
registerDevCommand := =>
    logDebug("[WatchMode] Registering dev command")
    devAction := async (): Promise<void> =>
        logDebug("[WatchMode] Executing dev action")
        cwd := process.cwd()
        opts := { ...defaultOpts, ...program.opts<Options>() }
        try
            console.log c.blue("Civetman starts building in watch modeâ€¦\n")
            { ctx, engine } := await runBuild(cwd, opts)
            console.log c.green("Initial build complete! Watching for changesâ€¦\n")
            
            saveStateAndSync := debounce(async =>
                logDebug("[STATE_SYNC] Starting state sync")
                ctx.prevHashes = { ...ctx.prevHashes, ...ctx.newHashes }
                ctx.newHashes = {}
                await saveNewState(ctx)
                await syncIDEConfigs(ctx)
                logDebug("[STATE_SYNC] State sync complete")
            , 800)

            logDebug("[WATCHER] Setting up watcher in directory:", path.resolve(cwd))
            watcher := createWatcher(cwd, opts)
            logDebug("[WATCHER] Watcher instance created:", !!watcher)
            attachWatchHandlers(
                watcher, 
                ctx, 
                cwd, 
                saveStateAndSync, 
                engine)
            
            // Register this watcher for global cleanup once
            activeWatchBundles.add({ watcher, ctx })
        catch e
            console.error c.red("Watch mode failed"), e
            process.exitCode = 1
    program.command "dev"
        .description "Watch .civet files and rebuild on change"
        .action devAction

export default () =>
    // top-level CLI wiring
    program
        .name "civetman"
        .description "Use Civet language in any project â€“ build or watch .civet files"
        .version "0.1.0"
        .option("-x, --tsx", "Generate .tsx files instead of .ts", defaultOpts.tsx)
        .option("--out-ts <dir>", "Directory to emit .ts files (repeatable or comma-separated)", collectDirs, [] as string[])
        .option("--out-tsx <dir>", "Directory to emit .tsx files (repeatable or comma-separated)", collectDirs, [] as string[])
        .option("--no-git-ignore", "Disable writing generated files to .gitignore")
        .option("--no-vscode-hide", "Disable hiding generated files in VS Code")
        .option("--inline-map <mode>", "Inline source map mode", defaultOpts.inlineMap)
        .option("--map-files", "Emit external .map files")
        .option("--concurrency <number>", "Max parallel compilations", (val) => parseInt(val, 10))
        .option("--force-polling", "Force chokidar polling even outside CI")
        .option("--ignore-folders <dir>", "Folder(s) to ignore (repeatable or comma-separated)", collectDirs, [] as string[])

    registerBuildCommand()
    registerDevCommand()

    program.parse(process.argv)

// Debounce helper â€“ immediate execution on first call (leading) and one batched tail call.
debounce := (func: Function, timeout = 1000) ->
    timer: NodeJS.Timeout | null .= null
    pendingArgs: any[] | null .= null
    (...args: any[]) ->
        logDebug("[DEBOUNCE] Debounce invoked", args)
        if !timer?
            // Leading edge â€“ fire immediately
            logDebug("[DEBOUNCE] Leading call executed")
            func(...args)
            // Start timer for potential trailing call
            timer = setTimeout (->
                if pendingArgs?
                    logDebug("[DEBOUNCE] Trailing batched call executed")
                    func(...pendingArgs)
                timer = null
                pendingArgs = null
            ), timeout
        else
            // While timer active, update the pending args for a single trailing call
            pendingArgs = args

export computeHash, resolveOutputType, defaultOpts